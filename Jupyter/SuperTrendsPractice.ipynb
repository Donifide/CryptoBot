{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "associate-shower",
   "metadata": {},
   "source": [
    "# Packages, dependencies, extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "insured-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "from IPython.display import clear_output\n",
    "#!pip install schedule\n",
    "\n",
    "#from config import rh_username,rh_password\n",
    "from my_config import rh_username,rh_password\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "import robin_stocks as r\n",
    "import schedule,time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "clear_output()\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attempted-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add color for a bit of class.\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    " \n",
    "#USAGE\n",
    "# f\"{bcolors.OKGREEN}STRING\\n{bcolors.ENDC}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-geometry",
   "metadata": {},
   "source": [
    "# Robinhood login & functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-contributor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://robin-stocks.readthedocs.io/en/latest/\n",
    "login = r.authentication.login(username=rh_username,password=rh_password,store_session=True)\n",
    "access_token=login['access_token']\n",
    "token_type=login['token_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recreational-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crypto functions for reference.\n",
    "\"\"\"Contains functions to get information about crypto-currencies.\"\"\"\n",
    "import robin_stocks.helper as helper\n",
    "import robin_stocks.urls as urls\n",
    "\n",
    "@helper.login_required\n",
    "def get_crypto_quote(symbol, info=None):\n",
    "    \"\"\"Gets information about a crypto including low price, high price, and open price\n",
    "    :param symbol: The crypto ticker.\n",
    "    :type symbol: str\n",
    "    :param info: Will filter the results to have a list of the values that correspond to key that matches info.\n",
    "    :type info: Optional[str]\n",
    "    :returns: [dict] If info parameter is left as None then the list will contain a dictionary of key/value pairs for each ticker. \\\n",
    "    Otherwise, it will be a list of strings where the strings are the values of the key that corresponds to info.\n",
    "    :Dictionary Keys: * ask_price\n",
    "                      * bid_price\n",
    "                      * high_price\n",
    "                      * id\n",
    "                      * low_price\n",
    "                      * mark_price\n",
    "                      * open_price\n",
    "                      * symbol\n",
    "                      * volume\n",
    " \n",
    "    \"\"\"\n",
    "    id = get_crypto_info(symbol, info='id')\n",
    "    url = urls.crypto_quote(id)\n",
    "    data = helper.request_get(url)\n",
    "    return(helper.filter_data(data, info))\n",
    "\n",
    "@helper.login_required\n",
    "def get_crypto_historicals(symbol, interval='hour', span='week', bounds='24_7', info=None):\n",
    "    \"\"\"Gets historical information about a crypto including open price, close price, high price, and low price.\n",
    "    :param symbol: The crypto ticker.\n",
    "    :type symbol: str\n",
    "    :param interval: The time between data points. Can be '15second', '5minute', '10minute', 'hour', 'day', or 'week'. Default is 'hour'.\n",
    "    :type interval: str\n",
    "    :param span: The entire time frame to collect data points. Can be 'hour', 'day', 'week', 'month', '3month', 'year', or '5year'. Default is 'week'\n",
    "    :type span: str\n",
    "    :param bound: The times of day to collect data points. 'Regular' is 6 hours a day, 'trading' is 9 hours a day, \\\n",
    "    'extended' is 16 hours a day, '24_7' is 24 hours a day. Default is '24_7'\n",
    "    :type bound: str\n",
    "    :param info: Will filter the results to have a list of the values that correspond to key that matches info.\n",
    "    :type info: Optional[str]\n",
    "    :returns: [list] If info parameter is left as None then the list will contain a dictionary of key/value pairs for each ticker. \\\n",
    "    Otherwise, it will be a list of strings where the strings are the values of the key that corresponds to info.\n",
    "    :Dictionary Keys: * begins_at\n",
    "                      * open_price\n",
    "                      * close_price\n",
    "                      * high_price\n",
    "                      * low_price\n",
    "                      * volume\n",
    "                      * session\n",
    "                      * interpolated\n",
    "                      * symbol\n",
    "    \"\"\"\n",
    "    interval_check = ['15second', '5minute', '10minute', 'hour', 'day', 'week']\n",
    "    span_check = ['hour', 'day', 'week', 'month', '3month', 'year', '5year']\n",
    "    bounds_check = ['24_7', 'extended', 'regular', 'trading']\n",
    "\n",
    "    if interval not in interval_check:\n",
    "        print(\n",
    "            'ERROR: Interval must be \"15second\",\"5minute\",\"10minute\",\"hour\",\"day\",or \"week\"', file=helper.get_output())\n",
    "        return([None])\n",
    "    if span not in span_check:\n",
    "        print('ERROR: Span must be \"hour\",\"day\",\"week\",\"month\",\"3month\",\"year\",or \"5year\"', file=helper.get_output())\n",
    "        return([None])\n",
    "    if bounds not in bounds_check:\n",
    "        print('ERROR: Bounds must be \"24_7\",\"extended\",\"regular\",or \"trading\"', file=helper.get_output())\n",
    "        return([None])\n",
    "    if (bounds == 'extended' or bounds == 'trading') and span != 'day':\n",
    "        print('ERROR: extended and trading bounds can only be used with a span of \"day\"', file=helper.get_output())\n",
    "        return([None])\n",
    "\n",
    "\n",
    "    symbol = helper.inputs_to_set(symbol)\n",
    "    id = get_crypto_info(symbol[0], info='id')\n",
    "    url = urls.crypto_historical(id)\n",
    "    payload = {'interval': interval,\n",
    "               'span': span,\n",
    "               'bounds': bounds}\n",
    "    data = helper.request_get(url, 'regular', payload)\n",
    "\n",
    "    histData = []\n",
    "    cryptoSymbol = data['symbol']\n",
    "    for subitem in data['data_points']:\n",
    "        subitem['symbol'] = cryptoSymbol\n",
    "        histData.append(subitem)\n",
    "\n",
    "    return(helper.filter_data(histData, info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-bones",
   "metadata": {},
   "source": [
    "# SuperTrend application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-attitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching new data for 2021-09-01T00:48:47.928713\n",
      "Fetching new data for 2021-09-01T00:48:58.256031\n",
      "Fetching new data for 2021-09-01T00:49:08.594785\n",
      "Fetching new data for 2021-09-01T00:49:18.984228\n",
      "Fetching new data for 2021-09-01T00:49:29.479705\n",
      "Fetching new data for 2021-09-01T00:49:39.783973\n",
      "Fetching new data for 2021-09-01T00:49:50.115395\n",
      "Fetching new data for 2021-09-01T00:50:00.641083\n",
      "Fetching new data for 2021-09-01T00:50:11.199811\n",
      "Fetching new data for 2021-09-01T00:50:21.540888\n",
      "Fetching new data for 2021-09-01T00:50:38.096766\n",
      "Fetching new data for 2021-09-01T00:50:51.215579\n",
      "Fetching new data for 2021-09-01T00:51:03.575803\n",
      "Fetching new data for 2021-09-01T00:51:16.581919\n",
      "Fetching new data for 2021-09-01T00:51:30.124933\n",
      "Fetching new data for 2021-09-01T00:51:40.650074\n",
      "Fetching new data for 2021-09-01T00:51:51.179036\n",
      "Fetching new data for 2021-09-01T00:52:01.633201\n",
      "Fetching new data for 2021-09-01T00:52:12.468552\n",
      "Fetching new data for 2021-09-01T00:52:22.963611\n",
      "Fetching new data for 2021-09-01T00:52:33.406353\n",
      "Fetching new data for 2021-09-01T00:52:43.909716\n",
      "Fetching new data for 2021-09-01T00:52:54.322515\n",
      "Fetching new data for 2021-09-01T00:53:04.715041\n",
      "Fetching new data for 2021-09-01T00:53:15.146515\n",
      "Fetching new data for 2021-09-01T00:53:25.541202\n",
      "Fetching new data for 2021-09-01T00:53:36.001646\n",
      "Fetching new data for 2021-09-01T00:53:40.478976\n",
      "\n",
      "Fetching new data for 2021-09-01T00:53:46.904270\n",
      "Fetching new data for 2021-09-01T00:53:57.306724\n",
      "Fetching new data for 2021-09-01T00:54:07.724702\n",
      "Fetching new data for 2021-09-01T00:54:18.186975\n",
      "Fetching new data for 2021-09-01T00:54:28.616853\n",
      "Fetching new data for 2021-09-01T00:54:39.036378\n",
      "Fetching new data for 2021-09-01T00:54:49.441285\n",
      "Fetching new data for 2021-09-01T00:54:59.855358\n",
      "Fetching new data for 2021-09-01T00:55:10.283161\n",
      "Fetching new data for 2021-09-01T00:55:20.669582\n",
      "Fetching new data for 2021-09-01T00:55:31.026365\n",
      "Fetching new data for 2021-09-01T00:55:41.446603\n",
      "Fetching new data for 2021-09-01T00:55:51.851059\n",
      "Fetching new data for 2021-09-01T00:56:02.334064\n",
      "Fetching new data for 2021-09-01T00:56:12.741467\n",
      "Fetching new data for 2021-09-01T00:56:23.130253\n",
      "Fetching new data for 2021-09-01T00:56:33.673430\n",
      "Fetching new data for 2021-09-01T00:56:44.098225\n",
      "Fetching new data for 2021-09-01T00:56:54.857723\n",
      "Fetching new data for 2021-09-01T00:57:05.287932\n",
      "Fetching new data for 2021-09-01T00:57:15.725347\n",
      "Fetching new data for 2021-09-01T00:57:26.158945\n",
      "Fetching new data for 2021-09-01T00:57:36.809952\n",
      "Fetching new data for 2021-09-01T00:57:47.254033\n",
      "Fetching new data for 2021-09-01T00:57:57.707675\n",
      "Fetching new data for 2021-09-01T00:58:08.139769\n",
      "Fetching new data for 2021-09-01T00:58:18.561160\n",
      "Fetching new data for 2021-09-01T00:58:29.014876\n",
      "Fetching new data for 2021-09-01T00:58:39.569386\n",
      "Fetching new data for 2021-09-01T00:58:41.055821\n",
      "\n",
      "Fetching new data for 2021-09-01T00:58:50.496372\n",
      "Fetching new data for 2021-09-01T00:59:00.929117\n",
      "Fetching new data for 2021-09-01T00:59:11.336401\n",
      "Fetching new data for 2021-09-01T00:59:21.795757\n",
      "Fetching new data for 2021-09-01T00:59:32.273703\n",
      "Fetching new data for 2021-09-01T00:59:42.686068\n",
      "Fetching new data for 2021-09-01T00:59:53.100172\n",
      "Fetching new data for 2021-09-01T01:00:03.576817\n",
      "Fetching new data for 2021-09-01T01:00:13.985726\n",
      "Fetching new data for 2021-09-01T01:00:24.462716\n",
      "Fetching new data for 2021-09-01T01:00:34.868357\n",
      "Fetching new data for 2021-09-01T01:00:45.605998\n",
      "Fetching new data for 2021-09-01T01:00:56.044459\n",
      "Fetching new data for 2021-09-01T01:01:06.513634\n",
      "Fetching new data for 2021-09-01T01:01:16.960179\n",
      "Fetching new data for 2021-09-01T01:01:27.372306\n",
      "Fetching new data for 2021-09-01T01:01:37.809873\n",
      "Fetching new data for 2021-09-01T01:01:48.260921\n",
      "Fetching new data for 2021-09-01T01:01:58.671916\n",
      "Fetching new data for 2021-09-01T01:02:09.101592\n",
      "Fetching new data for 2021-09-01T01:02:19.564954\n",
      "Fetching new data for 2021-09-01T01:02:29.972438\n",
      "Fetching new data for 2021-09-01T01:02:40.444043\n",
      "Fetching new data for 2021-09-01T01:02:50.892559\n",
      "Fetching new data for 2021-09-01T01:03:01.323535\n",
      "Fetching new data for 2021-09-01T01:03:11.842137\n",
      "Fetching new data for 2021-09-01T01:03:22.280063\n",
      "Fetching new data for 2021-09-01T01:03:32.755092\n",
      "Fetching new data for 2021-09-01T01:03:42.191391\n",
      "\n",
      "Fetching new data for 2021-09-01T01:03:43.589070\n",
      "Fetching new data for 2021-09-01T01:03:53.988872\n",
      "Fetching new data for 2021-09-01T01:04:04.439460\n",
      "Fetching new data for 2021-09-01T01:04:14.965192\n",
      "Fetching new data for 2021-09-01T01:04:25.370384\n",
      "Fetching new data for 2021-09-01T01:04:35.801344\n",
      "Fetching new data for 2021-09-01T01:04:46.216607\n",
      "Fetching new data for 2021-09-01T01:04:56.982274\n",
      "Fetching new data for 2021-09-01T01:05:07.607451\n",
      "Fetching new data for 2021-09-01T01:05:18.061437\n",
      "Fetching new data for 2021-09-01T01:05:28.459725\n",
      "Fetching new data for 2021-09-01T01:05:38.925332\n",
      "Fetching new data for 2021-09-01T01:05:49.360497\n",
      "Fetching new data for 2021-09-01T01:05:59.760617\n",
      "Fetching new data for 2021-09-01T01:06:10.167148\n",
      "Fetching new data for 2021-09-01T01:06:20.681205\n",
      "Fetching new data for 2021-09-01T01:06:31.072920\n",
      "Fetching new data for 2021-09-01T01:06:41.430962\n"
     ]
    }
   ],
   "source": [
    "#SuperTrend\n",
    "def tr(data):\n",
    "    data['previous_close'] = data['close'].shift(1)\n",
    "    data['high-low'] = abs(data['high'] - data['low'])\n",
    "    data['high-pc'] = abs(data['high'] - data['previous_close'])\n",
    "    data['low-pc'] = abs(data['low'] - data['previous_close'])\n",
    "\n",
    "    tr = data[['high-low', 'high-pc', 'low-pc']].max(axis=1)\n",
    "\n",
    "    return tr\n",
    "\n",
    "def atr(data, period):\n",
    "    data['tr'] = tr(data)\n",
    "    atr = data['tr'].rolling(period).mean()\n",
    "\n",
    "    return atr\n",
    "\n",
    "def supertrend(df, period=7, atr_multiplier=3):\n",
    "    hl2 = (df['high'] + df['low']) / 2\n",
    "    df['atr'] = atr(df, period)\n",
    "    df['upperband'] = hl2 + (atr_multiplier * df['atr'])\n",
    "    df['lowerband'] = hl2 - (atr_multiplier * df['atr'])\n",
    "    df['in_uptrend'] = True\n",
    "\n",
    "    for current in range(1, len(df.index)):\n",
    "        previous = current - 1\n",
    "\n",
    "        if df['close'][current] > df['upperband'][previous]:\n",
    "            df['in_uptrend'][current] = True\n",
    "        elif df['close'][current] < df['lowerband'][previous]:\n",
    "            df['in_uptrend'][current] = False\n",
    "        else:\n",
    "            df['in_uptrend'][current] = df['in_uptrend'][previous]\n",
    "\n",
    "            if df['in_uptrend'][current] and df['lowerband'][current] < df['lowerband'][previous]:\n",
    "                df['lowerband'][current] = df['lowerband'][previous]\n",
    "\n",
    "            if not df['in_uptrend'][current] and df['upperband'][current] > df['upperband'][previous]:\n",
    "                df['upperband'][current] = df['upperband'][previous]\n",
    "        \n",
    "    return df\n",
    "\n",
    "#Simulation.\n",
    "#Assumes we're not in a position.\n",
    "in_position = False\n",
    "\n",
    "def signal(df):\n",
    "    global in_position\n",
    "\n",
    "    last_row_index = len(df.index) - 1\n",
    "    previous_row_index = last_row_index - 1\n",
    "    \n",
    "    #Downtrend > Uptrend: Buy\n",
    "    if not df['in_uptrend'][previous_row_index] and df['in_uptrend'][last_row_index]:\n",
    "        print(\"Buy\")\n",
    "        if not in_position:\n",
    "            #rh_buy.order(previous_close_price,below_high_price:True)\n",
    "            print(\"Bought\")\n",
    "            in_position = True\n",
    "        else:\n",
    "            print(\"already in position, nothing to do\")\n",
    "    \n",
    "    #Uptrend > Downtrend: Sell\n",
    "    if df['in_uptrend'][previous_row_index] and not df['in_uptrend'][last_row_index]:\n",
    "        if in_position:\n",
    "            print(\"Sell\")\n",
    "            #rh_sell.order(previous_close_price,pos_return:True)\n",
    "            print(\"Sold\")\n",
    "            in_position = False\n",
    "        else:\n",
    "            print(\"You aren't in position, nothing to sell\")\n",
    "\n",
    "def run_bot():\n",
    "    print(f\"\\nFetching new data for {datetime.now().isoformat()}\")\n",
    "    df = pd.DataFrame.from_dict(r.crypto.get_crypto_historicals('DOGE', interval='5minute', span='week', bounds='24_7', info=None)).drop(columns=['session','interpolated','symbol']).tail(100).reset_index(drop=True)\n",
    "    bar = []\n",
    "    for k,v in df.begins_at.items():\n",
    "        bar.append([str(time.mktime(datetime.strptime(v,\"%Y-%m-%dT%H:%M:%SZ\").timetuple()))[:12].replace('.','00'),df.open_price[k],df.high_price[k],df.low_price[k],df.close_price[k],df.volume[k]])\n",
    "    df = pd.DataFrame(bar[:-1], columns=['timestamp', 'open', 'high', 'low', 'close','volume'])\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    supertrend_data = supertrend(df)\n",
    "    signal(supertrend_data)\n",
    "    #pd.DataFrame(supertrend_data)\n",
    "\n",
    "schedule.every(300).seconds.do(run_bot)\n",
    "\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En fin..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
